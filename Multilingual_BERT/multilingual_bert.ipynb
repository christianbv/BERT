{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilingual BERT Text-classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forberedelser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/spacy/util.py:271: UserWarning: [W031] Model 'nb_core_news_sm' (2.2.5) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.0). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from data_representation import InputExample, InputFeatures, truncate_pairs\n",
    "from transformers import AutoTokenizer, BertModel, BertForSequenceClassification\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import torch\n",
    "from torch import nn\n",
    "import transformers as t\n",
    "from sklearn import metrics \n",
    "import metrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, \"../lib\")\n",
    "from text_processer import *\n",
    "\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import re\n",
    "from argparse import ArgumentParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD_LABELS = False\n",
    "DO_LOWER = False\n",
    "TRAINING_SIZE = 0.8\n",
    "MAX_LEN = 512\n",
    "EPOCHS = 1\n",
    "BATCHES = 1\n",
    "LR = 1e-5 \n",
    "EPS = 1e-8\n",
    "RANDOM_SEED = 42\n",
    "DEVICE = 'cpu'\n",
    "PRED_TRESH = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Path to a *BERT* model only. Can either be a pretrained version or a finetuned version\n",
    "\"\"\"\n",
    "MODEL_PATH = \"../hjemmesnekk/multilingual\" # Path to BertModel\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Path to a folder having both a finetuned BERT-version and trained dropout and classifier layers\n",
    "\"\"\"\n",
    "MODEL_PATH_TRAINED = \"../hjemmesnekk/multilingual-trained/25.08_16_labels_8_epochs\" # Path to BertModel\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Path to folder where the trained model is going to be saved. Doublecheck for possible duplication\n",
    "\"\"\"\n",
    "SAVE_PATH = f\"../hjemmesnekk/multilingual-trained/{datetime.date.today()}_{EPOCHS}_epochs\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Path to tokenizer, should not be changed\n",
    "\"\"\"\n",
    "TOKENIZER_PATH = \"../hjemmesnekk/multilingual\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    Path to config file, should not be changed\n",
    "\"\"\"\n",
    "CONFIG_PATH = \"../hjemmesnekk/multilingual/config.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file ../hjemmesnekk/multilingual/config.json\n",
      "INFO:transformers.configuration_utils:Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "INFO:transformers.tokenization_utils_base:Model name '../hjemmesnekk/multilingual' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming '../hjemmesnekk/multilingual' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "INFO:transformers.tokenization_utils_base:Didn't find file ../hjemmesnekk/multilingual/added_tokens.json. We won't load it.\n",
      "INFO:transformers.tokenization_utils_base:Didn't find file ../hjemmesnekk/multilingual/tokenizer.json. We won't load it.\n",
      "INFO:transformers.tokenization_utils_base:loading file ../hjemmesnekk/multilingual/vocab.txt\n",
      "INFO:transformers.tokenization_utils_base:loading file None\n",
      "INFO:transformers.tokenization_utils_base:loading file ../hjemmesnekk/multilingual/special_tokens_map.json\n",
      "INFO:transformers.tokenization_utils_base:loading file ../hjemmesnekk/multilingual/tokenizer_config.json\n",
      "INFO:transformers.tokenization_utils_base:loading file None\n"
     ]
    }
   ],
   "source": [
    "tokenizer = t.AutoTokenizer.from_pretrained(TOKENIZER_PATH, strip_accents = False, do_lower_case = DO_LOWER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modellskall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertMultiLabler(nn.Module):\n",
    "    \"\"\"\n",
    "        Class for multilabler BERT.\n",
    "        Uses normal BertModel in bottom, a dropout layer and a linear classifier on top.\n",
    "        \n",
    "        If param loadTrained is True, the model loads all three layers.\n",
    "        If param loadTrained is False, the model can either load a finetuned BERT layer with empty layers on top, \n",
    "        or just a pretrained BERT layer with empty layers on top. \n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, loadTrained = True):\n",
    "        super(BertMultiLabler, self).__init__()\n",
    "        \n",
    "        if loadTrained:\n",
    "            print(\"Loading pretrained model, i.e. model where all three layers are finetuned\")\n",
    "            checkpoint = torch.load(MODEL_PATH_TRAINED)\n",
    "            self.base_model = t.BertModel.from_pretrained(MODEL_PATH_TRAINED)\n",
    "            self.droput = self.load_state_dict(checkpoint[\"dropout_state_dict\"])\n",
    "            self.classifier = self.load_state_dict(checkpoint[\"classifier_state_dict\"])\n",
    "            self.optimizer = self.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        else:\n",
    "            print(\"Loading pretrained *BERT* model, but not pretrained classifier layer!\")\n",
    "            config = t.BertConfig.from_json_file(CONFIG_PATH)\n",
    "            self.base_model = t.BertModel.from_pretrained(MODEL_PATH)\n",
    "            self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "            self.classifier = nn.Linear(config.hidden_size, NUM_LABELS)\n",
    "            self.optimizer = torch.optim.Adam(params = self.parameters(), lr = LR)\n",
    "\n",
    "    def forward(self, input_ids, masks, tokens):\n",
    "        _, model_output = self.base_model(input_ids, attention_mask = masks, token_type_ids = tokens) # Model returns two params\n",
    "        dropout_output = self.dropout(model_output)\n",
    "        output = self.classifier(dropout_output)\n",
    "        return output\n",
    "    \n",
    "    \"\"\"\n",
    "        Saving the BERT model and the other layers seperately\n",
    "        Naive checker to assure that models is not overrided\n",
    "    \"\"\"\n",
    "    def save_model(self, override = False):\n",
    "        if not override and os.path.isdir(SAVE_PATH):\n",
    "            SAVE_PATH += f\"copy_{datetime.date.today()}/\"\n",
    "            \n",
    "        model.base_model.save_pretrained(SAVE_PATH)\n",
    "        torch.save({\n",
    "            \"dropout_state_dict\":self.dropout.state_dict(),\n",
    "            \"classifier_state_dict\":self.classifier.state_dict(),\n",
    "            \"optimizer_state_dict\":self.optimizer.state_dict()\n",
    "        }, SAVE_PATH)\n",
    "        print(\"Model saved successfully at: \", SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tapsfunksjon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return nn.BCEWithLogitsLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metoder for trening og validering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for _,data in tqdm(enumerate(train_loader, 0)):\n",
    "        ids = data['input_ids'].to(DEVICE, dtype = torch.long)\n",
    "        mask = data['masks'].to(DEVICE, dtype = torch.long)\n",
    "        token_type_ids = data['tokens'].to(DEVICE, dtype = torch.long)\n",
    "        targets = data['labels'].to(DEVICE, dtype = torch.float)\n",
    "        \n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "        model.optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        if _%10==0:\n",
    "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        \n",
    "        model.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        model.optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oppbygging av data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Data():\n",
    "    \"\"\"\n",
    "        Takes in finished parsed data\n",
    "        Creates instances to be used when training the model. \n",
    "    \"\"\"\n",
    "    def __init__(self, inputExamples, labels: list, tokenizer: t.tokenization_bert, MAX_LEN: int):\n",
    "        self.inputExamples = inputExamples\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.MAX_LEN = MAX_LEN\n",
    "        self.label_map = {label : i for i,label in enumerate(labels)}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputExamples)\n",
    "        \n",
    "    \"\"\" \n",
    "        Method to tokenize one instance in inputExamples.\n",
    "        Innebygget metode som tensordataset benytter seg av for å hente ut dataen\n",
    "    \"\"\"\n",
    "    def __getitem__(self, ind):\n",
    "        encoded_dict = self.tokenizer.encode_plus(self.inputExamples[ind].text_a,\n",
    "                                            add_special_tokens = True,\n",
    "                                            max_length = self.MAX_LEN,\n",
    "                                            pad_to_max_length = True,\n",
    "                                            return_attention_mask = True,\n",
    "                                            truncation = True\n",
    "                                            #return_tensors = 'pt',\n",
    "        )\n",
    "        input_ids = encoded_dict['input_ids']\n",
    "        masks = encoded_dict['attention_mask']\n",
    "        token_type_ids = encoded_dict['token_type_ids']\n",
    "        \n",
    "        labels = [0]*len(self.label_map.keys())\n",
    "        for label in self.inputExamples[ind].labels:\n",
    "            labels[self.label_map.get(label)] = 1            \n",
    "            \n",
    "        return {\n",
    "            \"text\":self.inputExamples[ind].text_a, # Legger til text i dataloaders for uthenting senere\n",
    "            \"input_ids\":torch.tensor(input_ids, dtype=torch.long),\n",
    "            \"masks\":torch.tensor(masks, dtype = torch.long),\n",
    "            \"tokens\":torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            \"labels\":torch.tensor(labels, dtype = torch.float)\n",
    "        }  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metoder for uthenting av data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Returns the labeled_data in its entirety\n",
    "\"\"\"\n",
    "def load_labeled_data(with_intents = True) -> pd.DataFrame:\n",
    "    if OLD_LABELS:\n",
    "        l_df = pd.read_csv(\"../hjemmesnekk/labeled_data/toppoppgaver.csv\").set_index(\"index\")\n",
    "        return l_df\n",
    "    else:\n",
    "        l_df = pd.read_csv(\"../hjemmesnekk/labeled_data/toppoppgaver_NYESTE.csv\")\n",
    "        l_df = metrics.convert_to_matrix(l_df).set_index(\"index\")\n",
    "        if not with_intents:\n",
    "            l_df.drop(INTENTS, axis = 1)\n",
    "        return l_df\n",
    "    \n",
    "\"\"\"\n",
    "    Filters the labeled_data on prespecified columns\n",
    "    Removes instances that are not labelled\n",
    "    Removes df instances that are not in l_df\n",
    "    Returns df and l_df\n",
    "\"\"\"\n",
    "def filter_labeled_data(df: pd.DataFrame, l_df: pd.DataFrame, cols: list = None):\n",
    "    cols_to_use = cols if cols != None else l_df.columns.values\n",
    "    l_df = l_df[cols_to_use]\n",
    "    l_df[\"sum\"] = l_df.sum(axis = 1)\n",
    "    l_df = l_df[l_df[\"sum\"] >= 1.0].drop(\"sum\", axis = 1)\n",
    "    \n",
    "    df = df.loc[l_df.index.values,:]\n",
    "    df.sort_index(axis = 0, inplace = True)\n",
    "    l_df.sort_index(axis = 0, inplace = True)\n",
    "    return df, l_df\n",
    "\n",
    "def load_data(preprocessed = True) -> pd.DataFrame:\n",
    "    t = text_processer(TOPPOPPGAVER)\n",
    "    if preprocessed:\n",
    "        return t.get_preprocessed_data()\n",
    "    else:\n",
    "        return t.get_cleaned_data()\n",
    "\n",
    "def drop_cols(df, cols:list) -> pd.DataFrame:\n",
    "    for col in df.columns.values:\n",
    "        if col not in cols: \n",
    "            raise TypeError(f'Col: {col} not in param {cols}')\n",
    "        assert col in cols\n",
    "    return df.drop(cols, axis = 1)\n",
    "\n",
    "\"\"\"\n",
    "    Method to create inputExamples \n",
    "    Just instances with lemmatized texts and corresponding labels\n",
    "\"\"\"\n",
    "def createInputExamples(df, l_df, preprocessed = True):\n",
    "    inputExamples = []   \n",
    "    for i, val in enumerate(df[\"sentences\"].values):\n",
    "        labels = l_df.columns.values[np.where(l_df.values[i] == 1)]\n",
    "        inputExamples.append(InputExample(i, val[0:MAX_LEN], None, labels))\n",
    "    return inputExamples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metoder for parsing av data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denne må legges inn en JSON fil etterhvert - og helst kjøres ved preprosessering av data.\n",
    "def lemmatize(x, do_lower = False):\n",
    "    x = x.lower() if do_lower else x\n",
    "    \n",
    "    lemmas = {\"vedrørende\":r'(\\bvedr[.]?)',\n",
    "              \"angående\":r'(\\bang.)',\n",
    "              \"angående\":r'(\\bang.)',\n",
    "              \"telefon\":r'(\\btlf[.]?)',\n",
    "              \"offentlig\":r'(\\boff.)',\n",
    "              \"konto\":r'(\\bkto.)',\n",
    "              \"kontonummer\":r'(\\bkontonr.)',\n",
    "              \"på grunn av \": r'(\\bpga.)',\n",
    "              \"nummer\":r'(\\bnr[.]?)',\n",
    "              \"registrere\":r'(\\breg.)',\n",
    "              \"tidligere\":r'(\\btidl[.]?)',\n",
    "              \"med vennlig hilsen\":r'(\\bmvh[.]?)',\n",
    "              \"utbetaling\": r'\\butbet+al[ingenrt]*|(\\butbet[.]?)',\n",
    "              \"dagpenger\": r'\\bdagpeng[aenr]{0,3}',\n",
    "              \"finne\": r'(\\bfinne[r]?)',\n",
    "              \"ferie\": r'\\bferie[ern]*',\n",
    "              \"arbeide\": r'\\barbeide[ret]{1,3}',\n",
    "              \"korona\": r'(\\bcorona[viruset]{0,6}\\Z)|(\\bkorona[viruset]{0,6}\\Z)|(\\bcovid[-19]{0,3}\\Z)',\n",
    "              \"lege\": r'(\\blegen?)',\n",
    "              \"fastlege\": r'(\\bfastlegen)',\n",
    "              \"melding\": r'(\\bmld)|(\\bmelding[enr]{0,3})',\n",
    "              \"lønn\": r'(\\blønn[nea]{0,3})',\n",
    "              \"pensjon\": r'(\\bpensjon[en]{0,2})|(\\bpension[en]{0,2})',\n",
    "              \"informasjon\": r'(\\binformasjon[en]{0,2})|(\\binfo[.]?)',\n",
    "              \"kontonummer\": r'(\\bkontonummer[et]{0,2})|(\\bkontonr[.]?)',\n",
    "              \"oppdatere\": r'(\\boppdatert)|(\\boppdatering)',\n",
    "              \"dokument\": r'(\\bdokument[ern]{0,3})|(\\bdok)(|\\bdoc)',\n",
    "              \"aktivitetsplan\": r'(\\bak?tivitets?plan[en]{0,3})',\n",
    "              \"endre\": r'(\\bendre)|(\\bendring)',\n",
    "              \"ettersende\": r'(\\bettersende?)|({\\bettersending})',\n",
    "              \"arbeidsledig\":r'(\\barb. ledig)|(\\barb.ledig)',\n",
    "              \"arbeids\":r'(\\barb.)',\n",
    "              \"for eksempel\":r'(\\bf.eks.)|(\\bf. eks.)',\n",
    "              \". \":r'(\\b\\n)',\n",
    "    }\n",
    "    for key in lemmas.keys():\n",
    "        x = re.sub(lemmas[key], key, x)\n",
    "    return x\n",
    "\n",
    "def lemmatize_data(df: pd.DataFrame, preprocessed = True) -> pd.DataFrame:\n",
    "    pred = lambda x: lemmatize(x)\n",
    "    df[\"sentences\"] = df.raw_text.apply(pred) if preprocessed else df[\"Hva kom du hit for å gjøre\"].apply(pred)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lager DataLoaders og deler opp i treningsdata og testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Takes in inputExamples\n",
    "    Creates trainingset and testset by sampling from the inputExamples\n",
    "    Returns trainingset and labelset\n",
    "\"\"\"\n",
    "def split_data(inputExamples: list):\n",
    "    train_dataset = random.sample(inputExamples, int(TRAINING_SIZE*len(inputExamples)))\n",
    "    test_dataset = [inputExample for inputExample in inputExamples if inputExample not in train_dataset]\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def createDataLoaders(train_dataset, test_dataset, labels, tokenizer):\n",
    "    training_set = Custom_Data(train_dataset, labels, tokenizer, MAX_LEN\n",
    "    )\n",
    "    \n",
    "    test_set = Custom_Data(test_dataset,labels,tokenizer, MAX_LEN\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(training_set, shuffle = True, batch_size = BATCHES)\n",
    "    test_loader = DataLoader(test_set, sampler = SequentialSampler(test_set), batch_size = BATCHES)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kjører alt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kolonner for treningsdata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use_old = [\"Finne info/oversikt\", \"Ettersende dokumentasjon\", \"Permittert\", \"Sjekke/endre kontonr\", \"Finne skjema/dokumenter\",\"Oppdatere/lage cv\", \"Pensjon\", \"Ukjent\",\"Dagpenger\"]\n",
    "intent_cols = [\"Trekke/Fjerne\",\"Klage\",\"Spørsmål\",\"Finne\",\"Registrere/lage\",\"Endre/Oppdatere\",\"Søke\",\"Sjekke\",\"Sende\",\"@@@@@@@\",\"Ikke oppgitt\"]\n",
    "cols_to_use = [\"Annet\",\"Pensjon\",\"Dagpenger\",\"Skjema/søknad\",\"Utbetaling\",\"Dokumentasjon\",\"Tekniske problemer\",\"Permittert\",\"Personopplysning\",\"SPAM\",\"Informasjon\",\"Skatt/Årsoppgave\", \"Arbeidssøker\",\"Sykepenger\",\"Sykemelding\",\"CV\"]\n",
    "cols_to_use = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()\n",
    "l_df = load_labeled_data()\n",
    "df, l_df = filter_labeled_data(df, l_df, cols_to_use)\n",
    "NUM_LABELS = len(l_df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Størrelse data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saksbehandler/NAV      89\n",
      "Spørsmål              149\n",
      "Trekke/Fjerne          31\n",
      "Skatt/Årsoppgave       90\n",
      "Skjema/søknad         137\n",
      "Kontakte               44\n",
      "Registrere/lage       122\n",
      "Klage                  80\n",
      "Sjekke                269\n",
      "Søke                  101\n",
      "Personopplysning      140\n",
      "Sykepenger             42\n",
      "Sykemelding            69\n",
      "Tekniske problemer    140\n",
      "Barn/Foreldre          69\n",
      "@@@@@@@                68\n",
      "Utbetaling            130\n",
      "SPAM                   70\n",
      "Arbeidsgiver           64\n",
      "Veileder               30\n",
      "Meldekort              66\n",
      "Sende                 158\n",
      "Finne                 212\n",
      "Permittert            203\n",
      "Ikke oppgitt          879\n",
      "Annet                 320\n",
      "CV                     80\n",
      "Arbeidssøker           78\n",
      "Endre/Oppdatere       180\n",
      "Ufør/AAP               43\n",
      "Dokumentasjon         114\n",
      "Dagpenger             157\n",
      "Pensjon               197\n",
      "Informasjon           154\n",
      "Melding/brev           85\n",
      "Vedtak/Sak             86\n",
      "Annet språk            26\n",
      "Aktivitetsplan         33\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(l_df.sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parser dataen og lager DataLoaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = lemmatize_data(df, preprocessed = True)\n",
    "inputExamples = createInputExamples(df, l_df, preprocessed = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = split_data(inputExamples)\n",
    "train_loader, test_loader = createDataLoaders(train_data, test_data, l_df.columns.values, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialiserer modellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file ../hjemmesnekk/multilingual/config.json\n",
      "INFO:transformers.configuration_utils:Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file ../hjemmesnekk/multilingual/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained *BERT* model, but not pretrained classifier layer!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing BertModel.\n",
      "\n",
      "INFO:transformers.modeling_utils:All the weights of BertModel were initialized from the model checkpoint at ../hjemmesnekk/multilingual.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertMultiLabler(\n",
       "  (base_model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=39, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertMultiLabler(loadTrained = False)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trener modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.7036412358283997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:16, 16.26s/it]\u001b[A\n",
      "2it [00:32, 16.24s/it]\u001b[A\n",
      "3it [00:48, 16.22s/it]\u001b[A\n",
      "4it [01:04, 16.13s/it]\u001b[A\n",
      "5it [01:20, 16.05s/it]\u001b[A\n",
      "6it [01:36, 15.94s/it]\u001b[A\n",
      "7it [01:51, 15.93s/it]\u001b[A\n",
      "8it [02:07, 15.92s/it]\u001b[A\n",
      "9it [02:24, 16.01s/it]\u001b[A\n",
      "10it [02:40, 16.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.5543237328529358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11it [02:56, 16.15s/it]\u001b[A\n",
      "12it [03:13, 16.27s/it]\u001b[A\n",
      "13it [03:29, 16.22s/it]\u001b[A\n",
      "14it [03:45, 16.09s/it]\u001b[A\n",
      "15it [04:00, 15.89s/it]\u001b[A\n",
      "16it [04:16, 15.87s/it]\u001b[A\n",
      "17it [04:32, 15.88s/it]\u001b[A\n",
      "18it [04:47, 15.76s/it]\u001b[A\n",
      "19it [05:03, 15.63s/it]\u001b[A\n",
      "20it [05:19, 15.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.4611702263355255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "21it [05:35, 15.85s/it]\u001b[A\n",
      "22it [05:51, 15.95s/it]\u001b[A\n",
      "23it [06:17, 19.04s/it]\u001b[A\n",
      "24it [06:44, 21.37s/it]\u001b[A\n",
      "25it [07:11, 23.02s/it]\u001b[A\n",
      "26it [07:38, 24.28s/it]\u001b[A\n",
      "27it [08:05, 24.99s/it]\u001b[A\n",
      "28it [08:32, 25.82s/it]\u001b[A\n",
      "29it [08:59, 26.12s/it]\u001b[A\n",
      "30it [09:26, 26.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.4057311415672302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "31it [09:53, 26.48s/it]\u001b[A\n",
      "32it [10:20, 26.72s/it]\u001b[A\n",
      "33it [10:48, 27.14s/it]\u001b[A\n",
      "34it [11:16, 27.33s/it]\u001b[A\n",
      "35it [11:45, 27.66s/it]\u001b[A\n",
      "36it [12:12, 27.68s/it]\u001b[A\n",
      "37it [12:40, 27.55s/it]\u001b[A\n",
      "38it [13:08, 27.71s/it]\u001b[A\n",
      "39it [13:36, 27.77s/it]\u001b[A\n",
      "40it [14:04, 27.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.3711170554161072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "41it [14:30, 27.49s/it]\u001b[A\n",
      "42it [14:58, 27.66s/it]\u001b[A\n",
      "43it [15:27, 27.80s/it]\u001b[A\n",
      "44it [15:55, 28.06s/it]\u001b[A\n",
      "45it [16:24, 28.16s/it]\u001b[A\n",
      "46it [16:53, 28.42s/it]\u001b[A\n",
      "47it [17:20, 28.17s/it]\u001b[A\n",
      "48it [17:48, 27.94s/it]\u001b[A\n",
      "49it [18:16, 27.97s/it]\u001b[A\n",
      "50it [18:43, 27.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.3567408323287964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "51it [19:10, 27.53s/it]\u001b[A\n",
      "52it [19:37, 27.50s/it]\u001b[A\n",
      "53it [20:04, 27.18s/it]\u001b[A\n",
      "54it [20:32, 27.46s/it]\u001b[A\n",
      "55it [21:01, 27.87s/it]\u001b[A\n",
      "56it [21:30, 28.27s/it]\u001b[A\n",
      "57it [21:58, 28.35s/it]\u001b[A\n",
      "58it [22:27, 28.43s/it]\u001b[A\n",
      "59it [22:56, 28.44s/it]\u001b[A\n",
      "60it [23:24, 28.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.3385109603404999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "61it [23:51, 28.14s/it]\u001b[A\n",
      "62it [24:18, 27.64s/it]\u001b[A\n",
      "63it [24:45, 27.53s/it]\u001b[A\n",
      "64it [25:12, 27.28s/it]\u001b[A\n",
      "65it [25:40, 27.56s/it]\u001b[A\n",
      "66it [26:05, 26.76s/it]\u001b[A\n",
      "67it [26:29, 26.07s/it]\u001b[A\n",
      "68it [26:54, 25.55s/it]\u001b[A\n",
      "69it [27:18, 25.15s/it]\u001b[A\n",
      "70it [27:42, 24.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.3060429096221924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "71it [28:06, 24.58s/it]\u001b[A\n",
      "72it [28:30, 24.47s/it]\u001b[A\n",
      "73it [28:54, 24.31s/it]\u001b[A\n",
      "74it [29:18, 24.09s/it]\u001b[A\n",
      "75it [29:42, 24.30s/it]\u001b[A\n",
      "76it [30:07, 24.37s/it]\u001b[A\n",
      "77it [30:32, 24.64s/it]\u001b[A\n",
      "78it [30:57, 24.83s/it]\u001b[A\n",
      "79it [31:21, 24.51s/it]\u001b[A\n",
      "80it [31:46, 24.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.28614723682403564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "81it [32:11, 24.72s/it]\u001b[A\n",
      "82it [32:34, 24.35s/it]\u001b[A\n",
      "83it [32:57, 23.94s/it]\u001b[A\n",
      "84it [33:20, 23.65s/it]\u001b[A\n",
      "85it [33:44, 23.78s/it]\u001b[A\n",
      "86it [34:08, 23.61s/it]\u001b[A\n",
      "87it [34:31, 23.58s/it]\u001b[A\n",
      "88it [34:55, 23.56s/it]\u001b[A\n",
      "89it [35:18, 23.57s/it]\u001b[A\n",
      "90it [35:42, 23.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.2855275571346283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "91it [36:06, 23.68s/it]\u001b[A\n",
      "92it [36:29, 23.60s/it]\u001b[A\n",
      "93it [36:53, 23.51s/it]\u001b[A\n",
      "94it [37:05, 23.67s/it]\u001b[A\n",
      " 12%|█▎        | 1/8 [37:05<4:19:35, 2225.08s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.27422162890434265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:24, 24.18s/it]\u001b[A\n",
      "2it [00:47, 23.98s/it]\u001b[A\n",
      "3it [01:11, 23.98s/it]\u001b[A\n",
      "4it [01:35, 23.82s/it]\u001b[A\n",
      "5it [01:58, 23.72s/it]\u001b[A\n",
      "6it [02:21, 23.52s/it]\u001b[A\n",
      "7it [02:45, 23.52s/it]\u001b[A\n",
      "8it [03:08, 23.52s/it]\u001b[A\n",
      "10it [03:57, 24.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.291538804769516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11it [04:21, 24.03s/it]\u001b[A\n",
      "12it [04:45, 23.96s/it]\u001b[A\n",
      "13it [05:09, 24.10s/it]\u001b[A\n",
      "14it [05:33, 24.00s/it]\u001b[A\n",
      "15it [05:57, 24.06s/it]\u001b[A\n",
      "16it [06:22, 24.06s/it]\u001b[A\n",
      "17it [06:46, 24.15s/it]\u001b[A\n",
      "18it [07:10, 24.14s/it]\u001b[A\n",
      "19it [07:34, 24.03s/it]\u001b[A\n",
      "20it [07:58, 24.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.26991572976112366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "21it [08:22, 24.17s/it]\u001b[A\n",
      "22it [08:47, 24.18s/it]\u001b[A\n",
      "23it [09:10, 24.11s/it]\u001b[A\n",
      "24it [09:34, 24.05s/it]\u001b[A\n",
      "25it [09:56, 23.22s/it]\u001b[A\n",
      "26it [10:20, 23.58s/it]\u001b[A\n",
      "27it [10:44, 23.82s/it]\u001b[A\n",
      "28it [11:09, 23.92s/it]\u001b[A\n",
      "29it [11:33, 23.93s/it]\u001b[A\n",
      "30it [11:56, 23.92s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.28847506642341614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "31it [12:20, 23.73s/it]\u001b[A\n",
      "32it [12:43, 23.69s/it]\u001b[A\n",
      "33it [13:07, 23.56s/it]\u001b[A\n",
      "34it [13:31, 23.87s/it]\u001b[A\n",
      "35it [13:56, 24.03s/it]\u001b[A\n",
      "36it [14:20, 24.19s/it]\u001b[A\n",
      "37it [14:43, 23.88s/it]\u001b[A\n",
      "38it [15:08, 24.07s/it]\u001b[A\n",
      "39it [15:32, 24.19s/it]\u001b[A\n",
      "40it [15:56, 24.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.2767688035964966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "41it [16:21, 24.22s/it]\u001b[A\n",
      "42it [16:45, 24.12s/it]\u001b[A\n",
      "43it [17:08, 23.89s/it]\u001b[A\n",
      "44it [17:31, 23.75s/it]\u001b[A\n",
      "45it [17:55, 23.70s/it]\u001b[A\n",
      "46it [18:19, 23.69s/it]\u001b[A\n",
      "47it [18:42, 23.69s/it]\u001b[A\n",
      "48it [19:06, 23.54s/it]\u001b[A\n",
      "49it [19:29, 23.57s/it]\u001b[A\n",
      "50it [19:52, 23.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.24737122654914856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "51it [20:16, 23.50s/it]\u001b[A\n",
      "52it [20:40, 23.63s/it]\u001b[A\n",
      "53it [21:04, 23.64s/it]\u001b[A\n",
      "54it [21:27, 23.67s/it]\u001b[A\n",
      "55it [21:51, 23.65s/it]\u001b[A\n",
      "56it [22:15, 23.66s/it]\u001b[A\n",
      "57it [22:38, 23.54s/it]\u001b[A\n",
      "58it [23:01, 23.56s/it]\u001b[A\n",
      "59it [23:27, 24.05s/it]\u001b[A\n",
      "60it [23:51, 24.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.2522413432598114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "61it [24:15, 24.20s/it]\u001b[A\n",
      "62it [24:40, 24.20s/it]\u001b[A\n",
      "63it [25:04, 24.25s/it]\u001b[A\n",
      "64it [25:29, 24.53s/it]\u001b[A\n",
      "65it [25:54, 24.63s/it]\u001b[A\n",
      "66it [26:18, 24.60s/it]\u001b[A\n",
      "67it [26:42, 24.35s/it]\u001b[A\n",
      "68it [27:06, 24.23s/it]\u001b[A\n",
      "69it [27:30, 23.98s/it]\u001b[A\n",
      "70it [27:53, 23.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.2571879029273987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "71it [28:17, 23.93s/it]\u001b[A\n",
      "72it [28:42, 24.12s/it]\u001b[A\n",
      "73it [29:07, 24.44s/it]\u001b[A\n",
      "74it [29:31, 24.42s/it]\u001b[A\n",
      "75it [29:56, 24.36s/it]\u001b[A\n",
      "76it [30:20, 24.39s/it]\u001b[A\n",
      "77it [30:45, 24.54s/it]\u001b[A\n",
      "78it [31:11, 24.85s/it]\u001b[A\n",
      "79it [31:35, 24.72s/it]\u001b[A\n",
      "80it [31:59, 24.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.26395392417907715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "81it [32:24, 24.54s/it]\u001b[A\n",
      "82it [32:48, 24.55s/it]\u001b[A\n",
      "83it [33:13, 24.61s/it]\u001b[A\n",
      "84it [33:38, 24.72s/it]\u001b[A\n",
      "85it [34:02, 24.49s/it]\u001b[A\n",
      "86it [34:26, 24.39s/it]\u001b[A\n",
      "87it [34:50, 24.15s/it]\u001b[A\n",
      "88it [35:13, 24.00s/it]\u001b[A\n",
      "89it [35:37, 23.91s/it]\u001b[A\n",
      "90it [36:00, 23.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss:  0.24983857572078705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "91it [36:24, 23.74s/it]\u001b[A\n",
      "92it [36:48, 23.80s/it]\u001b[A\n",
      "93it [37:11, 23.61s/it]\u001b[A\n",
      "94it [37:24, 23.88s/it]\u001b[A\n",
      " 25%|██▌       | 2/8 [1:14:29<3:43:06, 2231.02s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss:  0.250979483127594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:24, 24.17s/it]\u001b[A\n",
      "2it [00:48, 24.07s/it]\u001b[A\n",
      "3it [01:12, 24.24s/it]\u001b[A\n",
      "4it [01:37, 24.31s/it]\u001b[A\n",
      "5it [02:01, 24.22s/it]\u001b[A\n",
      "6it [02:25, 24.36s/it]\u001b[A\n",
      "7it [02:50, 24.40s/it]\u001b[A\n",
      "8it [03:14, 24.31s/it]\u001b[A\n",
      "9it [03:38, 24.39s/it]\u001b[A\n",
      "10it [04:03, 24.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss:  0.2423943132162094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11it [04:27, 24.36s/it]\u001b[A\n",
      "12it [04:51, 24.23s/it]\u001b[A\n",
      "13it [05:14, 23.95s/it]\u001b[A\n",
      "14it [05:38, 23.77s/it]\u001b[A\n",
      "15it [06:02, 24.01s/it]\u001b[A\n",
      "16it [06:27, 24.23s/it]\u001b[A\n",
      "17it [06:52, 24.47s/it]\u001b[A\n",
      "18it [07:17, 24.50s/it]\u001b[A\n",
      "19it [07:42, 24.71s/it]\u001b[A\n",
      "20it [08:07, 24.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss:  0.25814053416252136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "21it [08:32, 24.88s/it]\u001b[A\n",
      "22it [08:57, 25.06s/it]\u001b[A\n",
      "23it [09:23, 25.10s/it]\u001b[A\n",
      "24it [09:47, 24.96s/it]\u001b[A\n",
      "25it [10:11, 24.70s/it]\u001b[A\n",
      "26it [10:36, 24.69s/it]\u001b[A\n",
      "27it [10:59, 24.23s/it]\u001b[A\n",
      "28it [11:12, 20.94s/it]\u001b[A\n",
      "29it [11:24, 18.10s/it]\u001b[A\n",
      "30it [11:36, 16.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss:  0.23879064619541168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "31it [11:46, 14.55s/it]\u001b[A\n",
      "32it [11:57, 13.41s/it]\u001b[A\n",
      "33it [12:09, 12.93s/it]\u001b[A\n",
      "34it [12:24, 13.56s/it]\u001b[A\n",
      "35it [12:35, 12.75s/it]\u001b[A\n",
      "36it [12:46, 12.35s/it]\u001b[A\n",
      "37it [12:57, 11.91s/it]\u001b[A\n",
      "38it [13:08, 11.49s/it]\u001b[A\n",
      "39it [13:18, 11.23s/it]\u001b[A\n",
      "40it [13:29, 10.98s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss:  0.2341620773077011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "41it [13:39, 10.75s/it]\u001b[A\n",
      "42it [13:49, 10.69s/it]\u001b[A\n",
      "43it [14:00, 10.56s/it]\u001b[A\n",
      "44it [14:10, 10.51s/it]\u001b[A\n",
      "45it [14:19, 10.17s/it]\u001b[A\n",
      "46it [14:30, 10.24s/it]\u001b[A\n",
      "47it [14:39,  9.92s/it]\u001b[A\n",
      "48it [14:57, 12.19s/it]\u001b[A\n",
      "49it [15:21, 15.88s/it]\u001b[A\n",
      "50it [15:46, 18.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss:  0.24913237988948822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "51it [16:12, 20.73s/it]\u001b[A\n",
      "52it [16:38, 22.35s/it]\u001b[A\n",
      "53it [17:03, 23.22s/it]\u001b[A\n",
      "54it [17:29, 23.93s/it]\u001b[A\n",
      "55it [17:54, 24.51s/it]\u001b[A\n",
      "56it [18:21, 25.00s/it]\u001b[A\n",
      "57it [18:47, 25.52s/it]\u001b[A\n",
      "58it [19:13, 25.52s/it]\u001b[A\n",
      "59it [19:38, 25.47s/it]\u001b[A\n",
      "60it [20:04, 25.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss:  0.26051875948905945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "61it [20:30, 25.60s/it]\u001b[A\n",
      "62it [20:55, 25.49s/it]\u001b[A\n",
      "63it [21:20, 25.41s/it]\u001b[A\n",
      "64it [21:44, 24.92s/it]\u001b[A\n",
      "65it [22:08, 24.60s/it]\u001b[A\n",
      "66it [22:32, 24.43s/it]\u001b[A\n",
      "67it [22:55, 24.24s/it]\u001b[A\n",
      "68it [23:19, 24.10s/it]\u001b[A\n",
      "69it [23:43, 24.01s/it]\u001b[A\n",
      "70it [24:07, 23.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss:  0.22295697033405304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "71it [24:31, 24.05s/it]\u001b[A\n",
      "72it [24:55, 24.01s/it]\u001b[A\n",
      "73it [25:19, 24.03s/it]\u001b[A\n",
      "74it [25:43, 24.11s/it]\u001b[A\n",
      "75it [26:09, 24.61s/it]\u001b[A\n",
      "76it [26:36, 25.24s/it]\u001b[A\n",
      "77it [27:04, 26.00s/it]\u001b[A\n",
      "78it [27:33, 26.93s/it]\u001b[A\n",
      "79it [28:03, 27.89s/it]\u001b[A\n",
      "80it [28:32, 28.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss:  0.242499440908432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "81it [29:01, 28.56s/it]\u001b[A\n",
      "82it [29:30, 28.58s/it]\u001b[A\n",
      "83it [29:58, 28.39s/it]\u001b[A\n",
      "84it [30:26, 28.22s/it]\u001b[A\n",
      "85it [30:53, 28.14s/it]\u001b[A\n",
      "86it [31:21, 28.04s/it]\u001b[A\n",
      "87it [31:49, 27.99s/it]\u001b[A\n",
      "88it [32:17, 27.97s/it]\u001b[A\n",
      "89it [32:46, 28.16s/it]\u001b[A\n",
      "90it [33:13, 27.85s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss:  0.2379760593175888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "91it [33:29, 24.31s/it]\u001b[A\n",
      "92it [33:45, 21.86s/it]\u001b[A\n",
      "93it [34:01, 20.05s/it]\u001b[A\n",
      "94it [34:09, 21.80s/it]\u001b[A\n",
      " 38%|███▊      | 3/8 [1:48:39<3:01:22, 2176.42s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss:  0.21974489092826843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:16, 16.62s/it]\u001b[A\n",
      "2it [00:32, 16.37s/it]\u001b[A\n",
      "3it [00:48, 16.25s/it]\u001b[A\n",
      "4it [01:03, 16.04s/it]\u001b[A\n",
      "5it [01:19, 15.91s/it]\u001b[A\n",
      "6it [01:35, 15.89s/it]\u001b[A\n",
      "7it [01:51, 15.92s/it]\u001b[A\n",
      "8it [02:07, 15.96s/it]\u001b[A\n",
      "9it [02:23, 15.90s/it]\u001b[A\n",
      "10it [02:38, 15.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss:  0.21292592585086823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11it [02:54, 15.85s/it]\u001b[A\n",
      "12it [03:10, 15.90s/it]\u001b[A\n",
      "13it [03:26, 15.97s/it]\u001b[A\n",
      "14it [03:43, 16.03s/it]\u001b[A\n",
      "15it [03:59, 16.03s/it]\u001b[A\n",
      "16it [04:15, 16.00s/it]\u001b[A\n",
      "17it [04:31, 16.08s/it]\u001b[A\n",
      "18it [04:47, 16.12s/it]\u001b[A\n",
      "19it [05:03, 16.12s/it]\u001b[A\n",
      "20it [05:19, 16.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss:  0.21894359588623047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "21it [05:35, 16.05s/it]\u001b[A\n",
      "22it [05:51, 15.86s/it]\u001b[A\n",
      "23it [06:07, 15.90s/it]\u001b[A\n",
      "24it [06:22, 15.87s/it]\u001b[A\n",
      "25it [06:38, 15.89s/it]\u001b[A\n",
      "26it [06:55, 16.04s/it]\u001b[A\n",
      "27it [07:11, 16.08s/it]\u001b[A\n",
      "28it [07:27, 16.05s/it]\u001b[A\n",
      "29it [07:43, 15.94s/it]\u001b[A\n",
      "30it [07:59, 15.96s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss:  0.20004713535308838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "31it [08:14, 15.74s/it]\u001b[A\n",
      "32it [08:30, 15.76s/it]\u001b[A\n",
      "33it [08:45, 15.69s/it]\u001b[A\n",
      "34it [09:01, 15.71s/it]\u001b[A\n",
      "35it [09:17, 15.75s/it]\u001b[A\n",
      "36it [09:32, 15.73s/it]\u001b[A\n",
      "37it [09:48, 15.69s/it]\u001b[A\n",
      "38it [10:04, 15.67s/it]\u001b[A\n",
      "39it [10:19, 15.64s/it]\u001b[A\n",
      "40it [10:35, 15.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss:  0.21249042451381683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "41it [10:50, 15.62s/it]\u001b[A\n",
      "42it [11:06, 15.68s/it]\u001b[A\n",
      "43it [11:22, 15.74s/it]\u001b[A\n",
      "44it [11:38, 15.81s/it]\u001b[A\n",
      "45it [11:54, 15.95s/it]\u001b[A\n",
      "46it [12:10, 15.87s/it]\u001b[A\n",
      "47it [12:26, 15.84s/it]\u001b[A\n",
      "48it [12:42, 15.91s/it]\u001b[A\n",
      "49it [12:58, 15.92s/it]\u001b[A\n",
      "50it [13:14, 15.93s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss:  0.23332588374614716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "51it [13:30, 15.91s/it]\u001b[A\n",
      "52it [13:46, 15.97s/it]\u001b[A\n",
      "53it [14:02, 16.01s/it]\u001b[A\n",
      "54it [14:18, 15.94s/it]\u001b[A\n",
      "55it [14:34, 15.93s/it]\u001b[A\n",
      "57it [15:05, 15.87s/it]\u001b[A\n",
      "58it [15:21, 15.83s/it]\u001b[A\n",
      "59it [15:36, 15.74s/it]\u001b[A\n",
      "60it [15:52, 15.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss:  0.1979328989982605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "61it [16:08, 15.75s/it]\u001b[A\n",
      "62it [16:24, 15.79s/it]\u001b[A\n",
      "63it [16:40, 15.80s/it]\u001b[A\n",
      "64it [16:56, 16.06s/it]\u001b[A\n",
      "65it [17:13, 16.20s/it]\u001b[A\n",
      "66it [17:29, 16.32s/it]\u001b[A\n",
      "67it [17:46, 16.33s/it]\u001b[A\n",
      "68it [18:02, 16.32s/it]\u001b[A\n",
      "69it [18:19, 16.44s/it]\u001b[A\n",
      "70it [18:36, 16.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss:  0.19834046065807343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "71it [18:52, 16.56s/it]\u001b[A\n",
      "72it [19:09, 16.54s/it]\u001b[A\n",
      "73it [19:25, 16.46s/it]\u001b[A\n",
      "74it [19:41, 16.44s/it]\u001b[A\n",
      "75it [19:58, 16.39s/it]\u001b[A\n",
      "76it [20:14, 16.32s/it]\u001b[A\n",
      "77it [20:30, 16.31s/it]\u001b[A\n",
      "78it [20:46, 16.12s/it]\u001b[A\n",
      "79it [21:01, 15.98s/it]\u001b[A\n",
      "80it [21:17, 16.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss:  0.18176913261413574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "81it [21:34, 16.08s/it]\u001b[A\n",
      "82it [21:51, 16.29s/it]\u001b[A\n",
      "83it [22:07, 16.37s/it]\u001b[A\n",
      "84it [22:23, 16.23s/it]\u001b[A\n",
      "85it [22:39, 16.19s/it]\u001b[A\n",
      "86it [22:55, 16.16s/it]\u001b[A\n",
      "87it [23:11, 16.14s/it]\u001b[A\n",
      "88it [23:27, 16.17s/it]\u001b[A\n",
      "89it [23:44, 16.14s/it]\u001b[A\n",
      "90it [24:00, 16.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss:  0.18668781220912933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "91it [24:16, 16.22s/it]\u001b[A\n",
      "92it [24:32, 16.26s/it]\u001b[A\n",
      "93it [24:49, 16.22s/it]\u001b[A\n",
      "94it [24:56, 15.92s/it]\u001b[A\n",
      " 50%|█████     | 4/8 [2:13:35<2:11:29, 1972.45s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss:  0.1821492612361908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:16, 16.30s/it]\u001b[A\n",
      "2it [00:31, 16.10s/it]\u001b[A\n",
      "3it [00:47, 15.99s/it]\u001b[A\n",
      "4it [01:02, 15.75s/it]\u001b[A\n",
      "5it [01:18, 15.62s/it]\u001b[A\n",
      "6it [01:33, 15.57s/it]\u001b[A\n",
      "7it [01:52, 16.42s/it]\u001b[A\n",
      "8it [02:10, 17.06s/it]\u001b[A\n",
      "9it [02:26, 16.62s/it]\u001b[A\n",
      "10it [02:35, 14.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss:  0.18608449399471283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11it [02:44, 12.72s/it]\u001b[A\n",
      "12it [02:53, 11.64s/it]\u001b[A\n",
      "13it [03:01, 10.59s/it]\u001b[A\n",
      "14it [03:10, 10.15s/it]\u001b[A\n",
      "15it [03:21, 10.38s/it]\u001b[A\n",
      "16it [03:35, 11.56s/it]\u001b[A\n",
      "17it [03:45, 10.88s/it]\u001b[A\n",
      "18it [03:55, 10.70s/it]\u001b[A\n",
      "19it [04:03,  9.94s/it]\u001b[A\n",
      "20it [04:12,  9.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss:  0.1507875621318817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "21it [04:26, 11.05s/it]\u001b[A\n",
      "22it [04:35, 10.16s/it]\u001b[A\n",
      "23it [04:44, 10.09s/it]\u001b[A\n",
      "24it [04:58, 10.99s/it]\u001b[A\n",
      "25it [05:06, 10.32s/it]\u001b[A\n",
      "26it [05:14,  9.62s/it]\u001b[A\n",
      "27it [05:23,  9.34s/it]\u001b[A\n",
      "28it [05:31,  8.96s/it]\u001b[A\n",
      "29it [05:46, 10.77s/it]\u001b[A\n",
      "30it [05:55, 10.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss:  0.2001989781856537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "31it [06:04,  9.92s/it]\u001b[A\n",
      "32it [06:13,  9.51s/it]\u001b[A\n",
      "33it [06:22,  9.46s/it]\u001b[A\n",
      "34it [06:30,  9.14s/it]\u001b[A\n",
      "35it [06:42,  9.95s/it]\u001b[A\n",
      "36it [06:57, 11.41s/it]\u001b[A\n",
      "37it [07:16, 13.58s/it]\u001b[A\n",
      "38it [07:30, 13.80s/it]\u001b[A\n",
      "39it [07:44, 13.92s/it]\u001b[A\n",
      "40it [07:59, 14.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss:  0.17035223543643951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "41it [08:13, 14.02s/it]\u001b[A\n",
      "42it [08:27, 14.17s/it]\u001b[A\n",
      "43it [08:41, 14.13s/it]\u001b[A\n",
      "44it [08:55, 14.16s/it]\u001b[A\n",
      "45it [09:09, 14.13s/it]\u001b[A\n",
      "46it [09:24, 14.21s/it]\u001b[A\n",
      "47it [09:38, 14.33s/it]\u001b[A\n",
      "48it [09:53, 14.33s/it]\u001b[A\n",
      "49it [10:07, 14.41s/it]\u001b[A\n",
      "50it [10:22, 14.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss:  0.17789433896541595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "52it [10:54, 15.37s/it]\u001b[A\n",
      "53it [11:11, 15.83s/it]\u001b[A\n",
      "54it [11:28, 16.16s/it]\u001b[A\n",
      "55it [11:45, 16.37s/it]\u001b[A\n",
      "56it [12:01, 16.39s/it]\u001b[A\n",
      "57it [12:17, 16.32s/it]\u001b[A\n",
      "58it [12:33, 16.19s/it]\u001b[A\n",
      "59it [12:49, 16.11s/it]\u001b[A\n",
      "60it [13:05, 16.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss:  0.17961150407791138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "61it [13:21, 16.10s/it]\u001b[A\n",
      "62it [13:37, 15.99s/it]\u001b[A\n",
      "63it [13:53, 16.03s/it]\u001b[A\n",
      "64it [14:09, 16.06s/it]\u001b[A\n",
      "65it [14:26, 16.10s/it]\u001b[A\n",
      "66it [14:42, 16.14s/it]\u001b[A\n",
      "67it [14:58, 16.16s/it]\u001b[A\n",
      "68it [15:14, 16.16s/it]\u001b[A\n",
      "69it [15:30, 16.20s/it]\u001b[A\n",
      "70it [15:47, 16.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss:  0.16045400500297546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "71it [16:03, 16.26s/it]\u001b[A\n",
      "72it [16:19, 16.17s/it]\u001b[A\n",
      "73it [16:35, 16.18s/it]\u001b[A\n",
      "74it [16:52, 16.28s/it]\u001b[A\n",
      "75it [17:08, 16.30s/it]\u001b[A\n",
      "76it [17:24, 16.27s/it]\u001b[A\n",
      "77it [17:40, 16.24s/it]\u001b[A\n",
      "78it [17:57, 16.20s/it]\u001b[A\n",
      "79it [18:13, 16.14s/it]\u001b[A\n",
      "80it [18:29, 16.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss:  0.16712982952594757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "81it [18:45, 16.09s/it]\u001b[A\n",
      "82it [19:01, 16.05s/it]\u001b[A\n",
      "83it [19:16, 16.00s/it]\u001b[A\n",
      "84it [19:33, 16.03s/it]\u001b[A\n",
      "85it [19:49, 16.01s/it]\u001b[A\n",
      "86it [20:05, 16.06s/it]\u001b[A\n",
      "87it [20:21, 16.02s/it]\u001b[A\n",
      "88it [20:36, 15.96s/it]\u001b[A\n",
      "89it [20:52, 15.92s/it]\u001b[A\n",
      "90it [21:14, 17.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss:  0.15928120911121368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "91it [21:40, 20.04s/it]\u001b[A\n",
      "92it [22:06, 22.10s/it]\u001b[A\n",
      "93it [22:33, 23.34s/it]\u001b[A\n",
      "94it [22:48, 14.56s/it]\u001b[A\n",
      " 62%|██████▎   | 5/8 [2:36:24<1:29:34, 1791.34s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss:  0.15222446620464325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:25, 25.93s/it]\u001b[A\n",
      "2it [00:45, 24.11s/it]\u001b[A\n",
      "3it [01:02, 21.74s/it]\u001b[A\n",
      "4it [01:17, 19.95s/it]\u001b[A\n",
      "5it [01:33, 18.68s/it]\u001b[A\n",
      "6it [01:49, 17.77s/it]\u001b[A\n",
      "7it [02:05, 17.22s/it]\u001b[A\n",
      "8it [02:20, 16.79s/it]\u001b[A\n",
      "9it [02:36, 16.42s/it]\u001b[A\n",
      "10it [02:52, 16.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss:  0.14255550503730774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11it [03:07, 16.08s/it]\u001b[A\n",
      "12it [03:23, 16.00s/it]\u001b[A\n",
      "13it [03:39, 15.92s/it]\u001b[A\n",
      "14it [03:55, 16.03s/it]\u001b[A\n",
      "15it [04:12, 16.19s/it]\u001b[A\n",
      "16it [04:28, 16.13s/it]\u001b[A\n",
      "17it [04:44, 16.11s/it]\u001b[A\n",
      "18it [05:00, 16.03s/it]\u001b[A\n",
      "19it [05:16, 15.97s/it]\u001b[A\n",
      "20it [05:32, 15.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss:  0.1562708616256714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "21it [05:48, 16.01s/it]\u001b[A\n",
      "22it [06:07, 17.01s/it]\u001b[A\n",
      "23it [06:31, 19.08s/it]\u001b[A\n",
      "24it [06:55, 20.69s/it]\u001b[A\n",
      "25it [07:19, 21.56s/it]\u001b[A\n",
      "26it [07:43, 22.40s/it]\u001b[A\n",
      "27it [08:05, 22.21s/it]\u001b[A\n",
      "28it [08:25, 21.46s/it]\u001b[A\n",
      "29it [08:45, 20.96s/it]\u001b[A\n",
      "30it [09:05, 20.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss:  0.1552208662033081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "31it [09:25, 20.56s/it]\u001b[A\n",
      "32it [09:49, 21.77s/it]\u001b[A\n",
      "33it [10:14, 22.74s/it]\u001b[A\n",
      "34it [10:40, 23.68s/it]\u001b[A\n",
      "35it [11:07, 24.47s/it]\u001b[A\n",
      "36it [11:33, 25.18s/it]\u001b[A\n",
      "37it [12:00, 25.63s/it]\u001b[A\n",
      "38it [12:26, 25.76s/it]\u001b[A\n",
      "39it [12:52, 25.73s/it]\u001b[A\n",
      "40it [13:18, 25.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss:  0.15067557990550995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "41it [13:43, 25.67s/it]\u001b[A\n",
      "42it [14:09, 25.78s/it]\u001b[A\n",
      "43it [14:35, 25.78s/it]\u001b[A\n",
      "44it [15:00, 25.36s/it]\u001b[A\n",
      "45it [15:26, 25.62s/it]\u001b[A\n",
      "46it [15:52, 25.67s/it]\u001b[A\n",
      "47it [16:17, 25.72s/it]\u001b[A\n",
      "48it [16:43, 25.55s/it]\u001b[A\n",
      "49it [17:08, 25.52s/it]\u001b[A\n",
      "50it [17:33, 25.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss:  0.1513025462627411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "51it [17:58, 25.26s/it]\u001b[A\n",
      "52it [18:24, 25.45s/it]\u001b[A\n",
      "53it [18:48, 25.16s/it]\u001b[A\n",
      "54it [19:13, 25.11s/it]\u001b[A\n",
      "55it [19:39, 25.18s/it]\u001b[A\n",
      "56it [20:03, 25.05s/it]\u001b[A\n",
      "57it [20:29, 25.17s/it]\u001b[A\n",
      "58it [20:54, 25.29s/it]\u001b[A\n",
      "59it [21:20, 25.26s/it]\u001b[A\n",
      "60it [21:45, 25.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss:  0.13400617241859436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "61it [22:10, 25.22s/it]\u001b[A\n",
      "62it [22:35, 25.22s/it]\u001b[A\n",
      "63it [23:00, 25.23s/it]\u001b[A\n",
      "64it [23:27, 25.49s/it]\u001b[A\n",
      "65it [23:51, 25.22s/it]\u001b[A\n",
      "66it [24:17, 25.56s/it]\u001b[A\n",
      "67it [24:43, 25.65s/it]\u001b[A\n",
      "68it [25:09, 25.62s/it]\u001b[A\n",
      "69it [25:35, 25.76s/it]\u001b[A\n",
      "70it [25:59, 25.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss:  0.15933069586753845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "71it [26:25, 25.36s/it]\u001b[A\n",
      "72it [26:49, 24.90s/it]\u001b[A\n",
      "73it [27:14, 25.10s/it]\u001b[A\n",
      "74it [27:38, 24.80s/it]\u001b[A\n",
      "75it [28:02, 24.41s/it]\u001b[A\n",
      "76it [28:26, 24.42s/it]\u001b[A\n",
      "77it [28:51, 24.56s/it]\u001b[A\n",
      "78it [29:15, 24.43s/it]\u001b[A\n",
      "79it [29:40, 24.44s/it]\u001b[A\n",
      "80it [30:03, 24.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss:  0.14140842854976654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "81it [30:28, 24.25s/it]\u001b[A\n",
      "82it [30:51, 23.99s/it]\u001b[A\n",
      "83it [31:16, 24.20s/it]\u001b[A\n",
      "84it [31:39, 23.91s/it]\u001b[A\n",
      "85it [32:04, 24.14s/it]\u001b[A\n",
      "86it [32:29, 24.40s/it]\u001b[A\n",
      "87it [32:52, 24.18s/it]\u001b[A\n",
      "88it [33:16, 24.08s/it]\u001b[A\n",
      "89it [33:41, 24.25s/it]\u001b[A\n",
      "90it [34:07, 24.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss:  0.1290232241153717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "91it [34:32, 24.95s/it]\u001b[A\n",
      "92it [34:58, 25.20s/it]\u001b[A\n",
      "93it [35:23, 25.22s/it]\u001b[A\n",
      "94it [35:39, 22.76s/it]\u001b[A\n",
      " 75%|███████▌  | 6/8 [3:12:03<1:03:11, 1895.71s/it]\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss:  0.1121104508638382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:24, 24.74s/it]\u001b[A\n",
      "2it [00:49, 24.73s/it]\u001b[A\n",
      "3it [01:14, 24.72s/it]\u001b[A\n",
      "4it [01:37, 24.44s/it]\u001b[A\n",
      "5it [02:01, 24.19s/it]\u001b[A\n",
      "6it [02:25, 24.12s/it]\u001b[A\n",
      "7it [02:48, 23.91s/it]\u001b[A\n",
      "8it [03:13, 24.04s/it]\u001b[A\n",
      "9it [03:37, 24.14s/it]\u001b[A\n",
      "10it [04:02, 24.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss:  0.13817858695983887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11it [04:26, 24.15s/it]\u001b[A\n",
      "12it [04:50, 24.08s/it]\u001b[A\n",
      "13it [05:13, 23.73s/it]\u001b[A\n",
      "14it [05:36, 23.76s/it]\u001b[A\n",
      "15it [06:01, 24.01s/it]\u001b[A\n",
      "16it [06:24, 23.73s/it]\u001b[A\n",
      "17it [06:48, 23.86s/it]\u001b[A\n",
      "18it [07:12, 23.85s/it]\u001b[A\n",
      "19it [07:36, 23.94s/it]\u001b[A\n",
      "20it [08:01, 24.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss:  0.13983368873596191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "21it [08:25, 24.16s/it]\u001b[A\n",
      "22it [08:50, 24.54s/it]\u001b[A\n",
      "23it [09:14, 24.39s/it]\u001b[A\n",
      "24it [09:35, 23.26s/it]\u001b[A\n",
      "25it [09:57, 22.79s/it]\u001b[A\n",
      "26it [10:18, 22.36s/it]\u001b[A\n",
      "27it [10:43, 23.10s/it]\u001b[A\n",
      "28it [11:07, 23.26s/it]\u001b[A\n",
      "29it [11:31, 23.53s/it]\u001b[A\n",
      "30it [11:56, 23.96s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss:  0.10831345617771149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "31it [12:20, 24.02s/it]\u001b[A\n",
      "32it [12:45, 24.33s/it]\u001b[A\n",
      "33it [13:08, 24.02s/it]\u001b[A\n",
      "34it [13:33, 24.26s/it]\u001b[A\n",
      "35it [13:57, 24.33s/it]\u001b[A\n",
      "36it [14:20, 23.91s/it]\u001b[A\n",
      "37it [14:45, 24.00s/it]\u001b[A\n",
      "38it [15:08, 23.92s/it]\u001b[A\n",
      "39it [15:34, 24.36s/it]\u001b[A\n",
      "40it [15:58, 24.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss:  0.11800697445869446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "41it [16:24, 24.79s/it]\u001b[A\n",
      "42it [16:49, 24.77s/it]\u001b[A\n",
      "43it [17:13, 24.63s/it]\u001b[A\n",
      "44it [17:37, 24.33s/it]\u001b[A\n",
      "45it [18:02, 24.73s/it]\u001b[A\n",
      "46it [18:28, 24.98s/it]\u001b[A\n",
      "47it [18:54, 25.26s/it]\u001b[A\n",
      "48it [19:20, 25.48s/it]\u001b[A\n",
      "49it [19:46, 25.70s/it]\u001b[A\n",
      "50it [20:12, 25.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss:  0.1381000131368637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "51it [20:39, 26.03s/it]\u001b[A\n",
      "52it [21:05, 26.16s/it]\u001b[A\n",
      "53it [21:31, 26.02s/it]\u001b[A\n",
      "54it [21:56, 25.88s/it]\u001b[A\n",
      "55it [22:21, 25.51s/it]\u001b[A\n",
      "56it [22:45, 25.14s/it]\u001b[A\n",
      "57it [23:10, 25.03s/it]\u001b[A\n",
      "58it [23:35, 24.97s/it]\u001b[A\n",
      "59it [23:58, 24.37s/it]\u001b[A\n",
      "60it [24:22, 24.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss:  0.11572851240634918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "61it [24:45, 24.01s/it]\u001b[A\n",
      "62it [25:10, 24.14s/it]\u001b[A\n",
      "63it [25:33, 23.94s/it]\u001b[A\n",
      "64it [25:57, 23.92s/it]\u001b[A\n",
      "65it [26:21, 23.92s/it]\u001b[A\n",
      "66it [26:45, 23.90s/it]\u001b[A\n",
      "67it [27:09, 24.09s/it]\u001b[A\n",
      "68it [27:33, 23.99s/it]\u001b[A\n",
      "69it [27:58, 24.22s/it]\u001b[A\n",
      "70it [28:23, 24.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss:  0.1152496486902237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "71it [28:49, 24.98s/it]\u001b[A\n",
      "72it [29:13, 24.59s/it]\u001b[A\n",
      "73it [29:36, 24.31s/it]\u001b[A\n",
      "74it [30:02, 24.57s/it]\u001b[A\n",
      "75it [30:25, 24.31s/it]\u001b[A\n",
      "76it [30:51, 24.59s/it]\u001b[A\n",
      "77it [31:15, 24.49s/it]\u001b[A\n",
      "78it [31:41, 24.96s/it]\u001b[A\n",
      "79it [32:05, 24.69s/it]\u001b[A\n",
      "80it [32:30, 24.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss:  0.12633533775806427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "81it [32:54, 24.54s/it]\u001b[A\n",
      "82it [33:19, 24.57s/it]\u001b[A\n",
      "83it [33:44, 24.81s/it]\u001b[A\n",
      "84it [34:10, 25.05s/it]\u001b[A\n",
      "85it [34:34, 24.96s/it]\u001b[A\n",
      "86it [35:00, 25.21s/it]\u001b[A\n",
      "87it [35:25, 25.02s/it]\u001b[A\n",
      "88it [35:50, 25.06s/it]\u001b[A\n",
      "89it [36:16, 25.34s/it]\u001b[A\n",
      "90it [36:41, 25.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss:  0.10931626707315445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "91it [37:06, 25.15s/it]\u001b[A\n",
      "92it [37:31, 25.11s/it]\u001b[A\n",
      "93it [37:56, 25.01s/it]\u001b[A\n",
      "94it [38:11, 24.38s/it]\u001b[A\n",
      " 88%|████████▊ | 7/8 [3:50:15<33:34, 2014.45s/it]  \n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss:  0.11520515382289886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:25, 25.41s/it]\u001b[A\n",
      "2it [00:48, 24.73s/it]\u001b[A\n",
      "3it [01:08, 23.39s/it]\u001b[A\n",
      "4it [01:28, 22.39s/it]\u001b[A\n",
      "5it [01:48, 21.49s/it]\u001b[A\n",
      "6it [02:07, 20.93s/it]\u001b[A\n",
      "7it [02:27, 20.56s/it]\u001b[A\n",
      "8it [02:46, 20.10s/it]\u001b[A\n",
      "9it [03:05, 19.76s/it]\u001b[A\n",
      "10it [03:24, 19.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss:  0.09802289307117462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "11it [03:44, 19.50s/it]\u001b[A\n",
      "12it [04:02, 19.25s/it]\u001b[A\n",
      "13it [04:21, 19.23s/it]\u001b[A\n",
      "14it [04:41, 19.26s/it]\u001b[A\n",
      "15it [05:00, 19.40s/it]\u001b[A\n",
      "16it [05:21, 19.71s/it]\u001b[A\n",
      "17it [05:41, 19.82s/it]\u001b[A\n",
      "18it [06:01, 19.94s/it]\u001b[A\n",
      "19it [06:21, 19.94s/it]\u001b[A\n",
      "20it [06:41, 19.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss:  0.10976696014404297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "21it [07:01, 20.00s/it]\u001b[A\n",
      "22it [07:21, 19.95s/it]\u001b[A\n",
      "23it [07:41, 20.03s/it]\u001b[A\n",
      "24it [08:02, 20.14s/it]\u001b[A\n",
      "25it [08:22, 20.09s/it]\u001b[A\n",
      "26it [08:42, 20.12s/it]\u001b[A\n",
      "27it [09:01, 19.93s/it]\u001b[A\n",
      "28it [09:21, 19.92s/it]\u001b[A\n",
      "29it [09:41, 19.89s/it]\u001b[A\n",
      "30it [10:01, 19.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss:  0.11670345813035965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "31it [10:21, 20.13s/it]\u001b[A\n",
      "32it [10:41, 20.09s/it]\u001b[A\n",
      "33it [11:01, 19.80s/it]\u001b[A\n",
      "34it [11:20, 19.66s/it]\u001b[A\n",
      "35it [11:39, 19.56s/it]\u001b[A\n",
      "36it [11:59, 19.54s/it]\u001b[A\n",
      "37it [12:18, 19.39s/it]\u001b[A\n",
      "38it [12:37, 19.26s/it]\u001b[A\n",
      "39it [12:56, 19.24s/it]\u001b[A\n",
      "40it [13:15, 19.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss:  0.09403642266988754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "41it [13:35, 19.29s/it]\u001b[A\n",
      "42it [13:54, 19.22s/it]\u001b[A\n",
      "43it [14:13, 19.16s/it]\u001b[A\n",
      "44it [14:32, 19.20s/it]\u001b[A\n",
      "45it [14:51, 19.26s/it]\u001b[A\n",
      "46it [15:12, 19.53s/it]\u001b[A\n",
      "47it [15:32, 19.72s/it]\u001b[A\n",
      "48it [15:51, 19.74s/it]\u001b[A\n",
      "49it [16:11, 19.66s/it]\u001b[A\n",
      "50it [16:31, 19.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss:  0.09390576183795929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "51it [16:51, 19.74s/it]\u001b[A\n",
      "52it [17:11, 19.81s/it]\u001b[A\n",
      "53it [17:31, 19.84s/it]\u001b[A\n",
      "54it [17:51, 20.05s/it]\u001b[A\n",
      "55it [18:11, 20.03s/it]\u001b[A\n",
      "56it [18:31, 20.00s/it]\u001b[A\n",
      "57it [18:48, 19.04s/it]\u001b[A\n",
      "58it [18:57, 16.01s/it]\u001b[A\n",
      "59it [19:07, 14.16s/it]\u001b[A\n",
      "60it [19:15, 12.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss:  0.08691537380218506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "61it [19:25, 11.69s/it]\u001b[A\n",
      "62it [19:33, 10.65s/it]\u001b[A\n",
      "63it [19:42, 10.22s/it]\u001b[A\n",
      "64it [19:51,  9.73s/it]\u001b[A\n",
      "65it [20:01,  9.86s/it]\u001b[A\n",
      "66it [20:13, 10.58s/it]\u001b[A\n",
      "67it [20:25, 10.78s/it]\u001b[A\n",
      "68it [20:36, 10.96s/it]\u001b[A\n",
      "69it [20:47, 10.95s/it]\u001b[A\n",
      "70it [20:59, 11.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss:  0.08015278726816177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "71it [21:10, 11.16s/it]\u001b[A\n",
      "72it [21:21, 11.15s/it]\u001b[A\n",
      "73it [21:32, 11.25s/it]\u001b[A\n",
      "74it [21:45, 11.55s/it]\u001b[A\n",
      "75it [21:55, 11.28s/it]\u001b[A\n",
      "76it [22:07, 11.26s/it]\u001b[A\n",
      "77it [22:17, 10.96s/it]\u001b[A\n",
      "78it [22:28, 11.04s/it]\u001b[A\n",
      "79it [22:39, 10.97s/it]\u001b[A\n",
      "80it [22:49, 10.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss:  0.11241193115711212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "81it [23:00, 10.88s/it]\u001b[A\n",
      "82it [23:12, 11.25s/it]\u001b[A\n",
      "83it [23:21, 10.49s/it]\u001b[A\n",
      "84it [23:32, 10.48s/it]\u001b[A\n",
      "85it [23:39,  9.68s/it]\u001b[A\n",
      "86it [23:48,  9.51s/it]\u001b[A\n",
      "87it [23:57,  9.10s/it]\u001b[A\n",
      "88it [24:06,  9.31s/it]\u001b[A\n",
      "89it [24:15,  8.93s/it]\u001b[A\n",
      "90it [24:24,  9.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss:  0.10598041117191315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "91it [24:32,  8.72s/it]\u001b[A\n",
      "92it [24:41,  8.92s/it]\u001b[A\n",
      "93it [24:49,  8.70s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lagrer modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'SAVE_PATH' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-cba3810bbad0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-354a0bbb5de7>\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(self, override)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mSAVE_PATH\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"copy_{datetime.date.today()}/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAVE_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         torch.save({\n\u001b[1;32m     45\u001b[0m             \u001b[0;34m\"dropout_state_dict\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'SAVE_PATH' referenced before assignment"
     ]
    }
   ],
   "source": [
    "model.save_model(override = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validerer modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kjører modellen på all dataen for å lage plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
